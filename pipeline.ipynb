{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Photometry Analysis\n",
    "\n",
    "The goal of this script is to:\n",
    "\n",
    "1. import photometry data and crop\n",
    "1. deinterleave data\n",
    "1. normalize photometry data for photobleaching\n",
    "1. chop up photometry data around keystrokes\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import and definition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import plotly.express as px\n",
    "from scipy.optimize import curve_fit\n",
    "from sklearn.linear_model import HuberRegressor\n",
    "\n",
    "\n",
    "IN_DATA = \"./data/data.csv\"\n",
    "IN_TS = \"./data/timestamp.csv\"\n",
    "PARAM_ROIS = [\"Region0G\"]\n",
    "PARAM_NFM_DISCARD = 100\n",
    "PARAM_LED_DICT = {7: \"initial\", 1: \"415nm\", 2: \"470nm\", 4: \"560nm\"}\n",
    "PARAM_EVT_RANGE = (-200, 400)\n",
    "\n",
    "\n",
    "def cut_df(df, nrow, sortby=\"Timestamp\"):\n",
    "    return df.sort_values(sortby).iloc[:nrow]\n",
    "\n",
    "\n",
    "def exp2(x, a, b, c, d, e):\n",
    "    return a * np.exp(b * x) + c * np.exp(d * x) + e\n",
    "\n",
    "\n",
    "def plot_signals(data):\n",
    "    dat_long = data[[\"Timestamp\", \"signal\"] + PARAM_ROIS].melt(\n",
    "        id_vars=[\"Timestamp\", \"signal\"], var_name=\"roi\", value_name=\"raw\"\n",
    "    )\n",
    "    return px.line(dat_long, x=\"Timestamp\", y=\"raw\", facet_row=\"roi\", color=\"signal\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ensure equal number of frames for each channel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(IN_DATA)\n",
    "ts = pd.read_csv(IN_TS, names=[\"Timestamp\", \"Key\", \"Time\"])\n",
    "data = data[data[\"FrameCounter\"] > PARAM_NFM_DISCARD].copy()\n",
    "data[\"signal\"] = data[\"LedState\"].map(PARAM_LED_DICT)\n",
    "nfm = data.groupby(\"signal\").size().min()\n",
    "data = (\n",
    "    data.groupby(\"signal\", group_keys=False)\n",
    "    .apply(cut_df, nrow=nfm)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "channels = np.unique(data[\"signal\"])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## visualize raw signal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_signals(data)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## correcting for photobleaching\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "order of operations:\n",
    "\n",
    "1. deinterleave data by flag (LED) and save into a matrix\n",
    "1. fit isosbestic signal with a biexponential decay -- the shape of this decay is a good approximation of the CONCENTRATION of GCaMP molecules underneath your fiber.\n",
    "   it decreases as the photobleach.\n",
    "   the amplitude, however, is tiny.\n",
    "   to adjust for this, we:\n",
    "1. linearly scale the fitted decay to the 470 data using robust fit.\n",
    "1. divide the raw 470 data by this scale fit to get a corrected signal\n",
    "\n",
    "note: this isn't dF/F but it is INTERNALLY reliable -- that is, you can compare the beginning of the recording to the end of the recording.\n",
    "dF/F requires a good approximation of baseline.\n",
    "you can use the `FP.no_led` as an underestimation of this -- or determine it empirically.\n",
    "it often isn't critical to a sound analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_415 = data[data[\"signal\"] == \"415nm\"].copy()\n",
    "x = np.linspace(0, 1, len(dat_415))\n",
    "dat_fit = dat_415.copy()\n",
    "dat_fit[\"signal\"] = \"415nm-fit\"\n",
    "sig_df_ls = [\n",
    "    data[data[\"signal\"] == sig].copy() for sig in set(channels) - set([\"415nm\"])\n",
    "]\n",
    "for roi in PARAM_ROIS:\n",
    "    popt, pcov = curve_fit(\n",
    "        exp2, x, dat_415[roi], p0=(1.0, -1.0, 1.0, -1.0, dat_415[roi].mean())\n",
    "    )\n",
    "    fit_415 = exp2(x, *popt)\n",
    "    dat_fit[roi] = fit_415\n",
    "    for sig_df in sig_df_ls:\n",
    "        sig_df[\"signal\"] = sig_df[\"signal\"] + \"-norm\"\n",
    "        model = HuberRegressor()\n",
    "        model.fit(fit_415.reshape((-1, 1)), sig_df[roi])\n",
    "        sig_df[roi] = sig_df[roi] - model.predict(fit_415.reshape((-1, 1)))\n",
    "data_norm = pd.concat([data, dat_fit] + sig_df_ls, ignore_index=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## visualize correction result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_signals(data_norm)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pool signals around `'Key'` events\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts[\"event\"] = ts[\"Key\"].astype(str)\n",
    "ts[\"evt_id\"] = ts[\"Timestamp\"].astype(str) + \"-\" + ts[\"event\"]\n",
    "data_join = data_norm.merge(ts, on=\"Timestamp\", how=\"left\")\n",
    "max_fm = data_join[\"FrameCounter\"].max()\n",
    "evt_df = []\n",
    "for _, dat_sig in data_join.groupby(\"signal\"):\n",
    "    for idx, row in dat_sig[dat_sig[\"evt_id\"].notnull()].iterrows():\n",
    "        fm = row[\"FrameCounter\"]\n",
    "        fm_range = tuple((np.array(PARAM_EVT_RANGE) + fm).clip(0, max_fm))\n",
    "        dat_sub = dat_sig[dat_sig[\"FrameCounter\"].between(*fm_range)].copy()\n",
    "        dat_sub[\"evt_fm\"] = dat_sub[\"FrameCounter\"] - fm\n",
    "        dat_sub[\"event\"] = row[\"event\"]\n",
    "        dat_sub[\"evt_id\"] = row[\"evt_id\"]\n",
    "        for roi in PARAM_ROIS:\n",
    "            mean = dat_sub.loc[dat_sub[\"evt_fm\"] < 0, roi].mean()\n",
    "            std = dat_sub.loc[dat_sub[\"evt_fm\"] < 0, roi].std()\n",
    "            if std > 0:\n",
    "                dat_sub[roi] = (dat_sub[roi] - mean) / std\n",
    "            else:\n",
    "                dat_sub[roi] = 0\n",
    "        evt_df.append(dat_sub)\n",
    "evt_df = pd.concat(evt_df, ignore_index=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## visualize signals around events\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(\n",
    "    evt_df,\n",
    "    x=\"evt_fm\",\n",
    "    y=\"Region0G\",\n",
    "    color=\"evt_id\",\n",
    "    facet_row=\"event\",\n",
    "    facet_col=\"signal\",\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neurophotometrics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
